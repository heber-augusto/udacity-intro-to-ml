{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvg0MDxxr3LlVF6BsoiNdh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heber-augusto/udacity-intro-to-ml/blob/master/naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6hAMTqm7Lsz",
        "colab_type": "text"
      },
      "source": [
        "This jupyter notebook was created during Intro to Machine Learning Udacity course.\n",
        "\n",
        "The goal at this notebook is to train and predict using naive bayes classifier.\n",
        "\n",
        "This notebook demonstrate:\n",
        "\n",
        " - Getting the dataset and putting its contents into google drive;\n",
        " - Trainning using scikit learn naive bayes classifier;\n",
        " - Print some timing and accuracy results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZHcdcZm8kwF",
        "colab_type": "text"
      },
      "source": [
        "The next cells mount google drive to colab notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4tYNnrBs2qf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8d30d6cc-58f1-43a3-b9b4-f080d70d31de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqYMjmH08zr0",
        "colab_type": "text"
      },
      "source": [
        "Changes the folder and git clone a repo (which was not used in this notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQN9X1FMs7Rn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcdfaf4c-1118-4d82-9494-17b64366c12e"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/repos\n",
        "!git clone https://github.com/heber-augusto/udacity-intro-to-ml\n",
        "%cd /content/drive/My\\ Drive/repos/udacity-intro-to-ml"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/repos/udacity-intro-to-ml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8et8d7LL8_pa",
        "colab_type": "text"
      },
      "source": [
        "Get the file containg datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1k48irctfFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -P ../udacity-intro-to-ml-files http://www.cs.cmu.edu/~./enron/enron_mail_20150507.tar.gz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0qTAkms9EGT",
        "colab_type": "text"
      },
      "source": [
        "Extract all files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLtf9xxst-fJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0eb60e2b-5232-4fa5-bc88-fc5d926d383b"
      },
      "source": [
        "print (\"unzipping Enron dataset (this may take a while)\")\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "tfile = tarfile.open(\"../udacity-intro-to-ml-files/enron_mail_20150507.tar.gz\", \"r:gz\")\n",
        "tfile.extractall(\"../udacity-intro-to-ml-files/.\")\n",
        "\n",
        "print (\"you're ready to go!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzipping Enron dataset (this may take a while)\n",
            "you're ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QAedW3D9Ki6",
        "colab_type": "text"
      },
      "source": [
        "The \"preprocess\" function is the same which is found inside github repository. The original version (from Udacity) was changed to a python3 and google colab compatible version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2pFus5_G_hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(\n",
        "    words_file = \"../tools/word_data.pkl\", \n",
        "    authors_file=\"../tools/email_authors.pkl\"):\n",
        "    \"\"\" \n",
        "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
        "        and the corresponding authors (by default email_authors.pkl) and performs\n",
        "        a number of preprocessing steps:\n",
        "            -- splits into training/testing sets (10% testing)\n",
        "            -- vectorizes into tfidf matrix\n",
        "            -- selects/keeps most helpful features\n",
        "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
        "        4 objects are returned:\n",
        "            -- training/testing features\n",
        "            -- training/testing labels\n",
        "    \"\"\"\n",
        "\n",
        "    ### the words (features) and authors (labels), already largely preprocessed\n",
        "    ### this preprocessing will be repeated in the text learning mini-project\n",
        "    authors_file_handler = open(authors_file, \"rb\")\n",
        "    authors = pickle.load(authors_file_handler)\n",
        "    authors_file_handler.close()\n",
        "\n",
        "    words_file_handler = open(words_file, \"rb\")\n",
        "    word_data = pickle.load(words_file_handler)\n",
        "    words_file_handler.close()\n",
        "\n",
        "    ### test_size is the percentage of events assigned to the test set\n",
        "    ### (remainder go into training)\n",
        "    features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "        word_data, \n",
        "        authors, \n",
        "        test_size=0.1, \n",
        "        random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "    ### text vectorization--go from strings to lists of numbers\n",
        "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
        "                                 stop_words='english')\n",
        "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
        "    features_test_transformed  = vectorizer.transform(features_test)\n",
        "\n",
        "\n",
        "\n",
        "    ### feature selection, because text is super high dimensional and \n",
        "    ### can be really computationally chewy as a result\n",
        "    selector = SelectPercentile(f_classif, percentile=10)\n",
        "    selector.fit(features_train_transformed, labels_train)\n",
        "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
        "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
        "\n",
        "    ### info on the data\n",
        "    print (f\"no. of Chris training emails: {sum(labels_train)}\")\n",
        "    print (f\"no. of Sara training emails: {len(labels_train)-sum(labels_train)}\")\n",
        "    \n",
        "    return features_train_transformed, features_test_transformed, labels_train, labels_test"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrM6P5h1z-Q8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "beabe2b3-dc35-4c58-847b-20593c543c71"
      },
      "source": [
        "features_train, features_test, labels_train, labels_test = preprocess(\n",
        "    words_file = \"./tools/word_data.pkl\", \n",
        "    authors_file=\"./tools/email_authors.pkl\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of Chris training emails: 7936\n",
            "no. of Sara training emails: 7884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfxlRJJMG2ue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eb860597-6086-4d48-c654-3520dd68cadd"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from time import time\n",
        "gnb = GaussianNB()\n",
        "\n",
        "t0 = time()\n",
        "model_trained = gnb.fit(features_train, labels_train)\n",
        "print (f\"training time: {round(time()-t0, 3)} s\")\n",
        "\n",
        "t1 = time()\n",
        "labels_pred = model_trained.predict(features_test)\n",
        "print (f\"prediction time: {round(time()-t1, 3)} s\")\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        "    % (features_test.shape[0], (labels_test != labels_pred).sum()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training time: 0.981 s\n",
            "prediction time: 0.107 s\n",
            "Number of mislabeled points out of a total 1758 points : 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPk8l1Om4qFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e521ade-9c68-4e82-d38b-2fc22b61b443"
      },
      "source": [
        "accuracy = (features_test.shape[0] - (labels_test != labels_pred).sum()) / features_test.shape[0]\n",
        "print (f\"accuracy: {accuracy}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9732650739476678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO3owtUA5zQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}