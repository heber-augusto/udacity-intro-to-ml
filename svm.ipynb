{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPflsK7MVzJnt4f8/ANQGNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heber-augusto/udacity-intro-to-ml/blob/master/svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6hAMTqm7Lsz",
        "colab_type": "text"
      },
      "source": [
        "This jupyter notebook was created during Intro to Machine Learning Udacity course.\n",
        "\n",
        "The goal at this notebook is to train and predict using SVM classifier.\n",
        "\n",
        "This notebook demonstrate:\n",
        "\n",
        " - Getting the dataset and putting its contents into google drive;\n",
        " - Trainning using scikit learn svm classifier;\n",
        " - Print some timing and accuracy results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZHcdcZm8kwF",
        "colab_type": "text"
      },
      "source": [
        "The next cells mount google drive to colab notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4tYNnrBs2qf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "66d2e6aa-de97-4ae2-8c15-9db817ac638c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqYMjmH08zr0",
        "colab_type": "text"
      },
      "source": [
        "Changes the folder and git clone a repo (which was not used in this notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQN9X1FMs7Rn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92217fcc-52c3-4493-df6a-324e9a841ffa"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/repos\n",
        "!git clone https://github.com/heber-augusto/udacity-intro-to-ml\n",
        "%cd /content/drive/My\\ Drive/repos/udacity-intro-to-ml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/repos/udacity-intro-to-ml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8et8d7LL8_pa",
        "colab_type": "text"
      },
      "source": [
        "Get the file containg datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1k48irctfFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -P ../udacity-intro-to-ml-files http://www.cs.cmu.edu/~./enron/enron_mail_20150507.tar.gz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0qTAkms9EGT",
        "colab_type": "text"
      },
      "source": [
        "Extract all files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLtf9xxst-fJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "effbdc8f-18be-446e-deb3-1c8c85cc485c"
      },
      "source": [
        "print (\"unzipping Enron dataset (this may take a while)\")\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "tfile = tarfile.open(\"../udacity-intro-to-ml-files/enron_mail_20150507.tar.gz\", \"r:gz\")\n",
        "tfile.extractall(\"../udacity-intro-to-ml-files/.\")\n",
        "\n",
        "print (\"you're ready to go!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzipping Enron dataset (this may take a while)\n",
            "you're ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QAedW3D9Ki6",
        "colab_type": "text"
      },
      "source": [
        "The \"preprocess\" function is the same which is found inside github repository. The original version (from Udacity) was changed to a python3 and google colab compatible version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2pFus5_G_hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(\n",
        "    words_file = \"../tools/word_data.pkl\", \n",
        "    authors_file=\"../tools/email_authors.pkl\"):\n",
        "    \"\"\" \n",
        "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
        "        and the corresponding authors (by default email_authors.pkl) and performs\n",
        "        a number of preprocessing steps:\n",
        "            -- splits into training/testing sets (10% testing)\n",
        "            -- vectorizes into tfidf matrix\n",
        "            -- selects/keeps most helpful features\n",
        "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
        "        4 objects are returned:\n",
        "            -- training/testing features\n",
        "            -- training/testing labels\n",
        "    \"\"\"\n",
        "\n",
        "    ### the words (features) and authors (labels), already largely preprocessed\n",
        "    ### this preprocessing will be repeated in the text learning mini-project\n",
        "    authors_file_handler = open(authors_file, \"rb\")\n",
        "    authors = pickle.load(authors_file_handler)\n",
        "    authors_file_handler.close()\n",
        "\n",
        "    words_file_handler = open(words_file, \"rb\")\n",
        "    word_data = pickle.load(words_file_handler)\n",
        "    words_file_handler.close()\n",
        "\n",
        "    ### test_size is the percentage of events assigned to the test set\n",
        "    ### (remainder go into training)\n",
        "    features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "        word_data, \n",
        "        authors, \n",
        "        test_size=0.1, \n",
        "        random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "    ### text vectorization--go from strings to lists of numbers\n",
        "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
        "                                 stop_words='english')\n",
        "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
        "    features_test_transformed  = vectorizer.transform(features_test)\n",
        "\n",
        "\n",
        "\n",
        "    ### feature selection, because text is super high dimensional and \n",
        "    ### can be really computationally chewy as a result\n",
        "    selector = SelectPercentile(f_classif, percentile=10)\n",
        "    selector.fit(features_train_transformed, labels_train)\n",
        "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
        "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
        "\n",
        "    ### info on the data\n",
        "    print (f\"no. of Chris training emails: {sum(labels_train)}\")\n",
        "    print (f\"no. of Sara training emails: {len(labels_train)-sum(labels_train)}\")\n",
        "    \n",
        "    return features_train_transformed, features_test_transformed, labels_train, labels_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrM6P5h1z-Q8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2b5af21a-eca5-4a1f-fa5c-267148a1b0db"
      },
      "source": [
        "features_train, features_test, labels_train, labels_test = preprocess(\n",
        "    words_file = \"./tools/word_data.pkl\", \n",
        "    authors_file=\"./tools/email_authors.pkl\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of Chris training emails: 7936\n",
            "no. of Sara training emails: 7884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe4hU0c9mj2p",
        "colab_type": "text"
      },
      "source": [
        "**Traing a SVM model with linear kernel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfxlRJJMG2ue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "53d3c832-b27d-418e-b261-25a51709b311"
      },
      "source": [
        "from sklearn import svm\n",
        "from time import time\n",
        "clf = svm.LinearSVC()\n",
        "\n",
        "t0 = time()\n",
        "model_trained = clf.fit(features_train, labels_train)\n",
        "print (f\"training time: {round(time()-t0, 3)} s\")\n",
        "\n",
        "t1 = time()\n",
        "labels_pred = model_trained.predict(features_test)\n",
        "print (f\"prediction time: {round(time()-t1, 3)} s\")\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        "    % (features_test.shape[0], (labels_test != labels_pred).sum()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training time: 0.38 s\n",
            "prediction time: 0.01 s\n",
            "Number of mislabeled points out of a total 1758 points : 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPk8l1Om4qFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19bbb03d-05dd-40c2-d672-1696922b1724"
      },
      "source": [
        "accuracy = (features_test.shape[0] - (labels_test != labels_pred).sum()) / features_test.shape[0]\n",
        "print (f\"accuracy: {accuracy}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9897610921501706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBCIcUtyr9RJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb54f82c-4956-49bc-ac29-0c69e428bc7d"
      },
      "source": [
        "features_train.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15820, 3785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj7lNmfhmCek",
        "colab_type": "text"
      },
      "source": [
        "**Reducing training dataset to 1% to compare the timming and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO3owtUA5zQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "783b841a-62ac-4f37-e3fa-aea75c8b6f3f"
      },
      "source": [
        "features_train_small = features_train[:int(features_train.shape[0]/100)]\n",
        "labels_train_small = labels_train[:int(len(labels_train)/100)]\n",
        "\n",
        "clf_small_training_set = svm.LinearSVC()\n",
        "\n",
        "t0 = time()\n",
        "model_trained_small = clf_small_training_set.fit(\n",
        "    features_train_small, \n",
        "    labels_train_small)\n",
        "print (f\"training time: {round(time()-t0, 3)} s\")\n",
        "\n",
        "t1 = time()\n",
        "labels_pred = model_trained_small.predict(features_test)\n",
        "print (f\"prediction time: {round(time()-t1, 3)} s\")\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        "    % (features_test.shape[0], (labels_test != labels_pred).sum()))\n",
        "\n",
        "accuracy = (features_test.shape[0] - (labels_test != labels_pred).sum()) / features_test.shape[0]\n",
        "print (f\"accuracy: {accuracy}\")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training time: 0.007 s\n",
            "prediction time: 0.01 s\n",
            "Number of mislabeled points out of a total 1758 points : 179\n",
            "accuracy: 0.8981797497155859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bporh_AmvVo",
        "colab_type": "text"
      },
      "source": [
        "**Train a SVM model with rbf kernel and just 1% of the training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHxNlHK5j1K2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c6fcbd7b-d205-42d5-8555-6ca46fe45428"
      },
      "source": [
        "clf_rbf = svm.SVC(kernel='rbf')\n",
        "\n",
        "t0 = time()\n",
        "model_trained_rbf = clf_rbf.fit(\n",
        "    features_train_small, \n",
        "    labels_train_small)\n",
        "print (f\"training time: {round(time()-t0, 3)} s\")\n",
        "\n",
        "t1 = time()\n",
        "labels_pred = model_trained_rbf.predict(features_test)\n",
        "print (f\"prediction time: {round(time()-t1, 3)} s\")\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        "    % (features_test.shape[0], (labels_test != labels_pred).sum()))\n",
        "\n",
        "accuracy = (features_test.shape[0] - (labels_test != labels_pred).sum()) / features_test.shape[0]\n",
        "print (f\"accuracy: {accuracy}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training time: 0.155 s\n",
            "prediction time: 1.574 s\n",
            "Number of mislabeled points out of a total 1758 points : 184\n",
            "accuracy: 0.8953356086461889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-so7mHt4pYZx",
        "colab_type": "text"
      },
      "source": [
        "**Grid search with different C values to check accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jK3wblmnWO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bb861db-78cd-46fa-cb3a-892f0c07dc3a"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "C_range = [10, 100, 1000., 10000.]\n",
        "parameters = {'kernel':('rbf',), 'C':C_range}\n",
        "svc = svm.SVC()\n",
        "grid = GridSearchCV(svc, parameters)\n",
        "grid.fit(\n",
        "    features_train_small, \n",
        "    labels_train_small)\n",
        "\n",
        "print(\"The best parameters are %s with a score of %0.2f\"\n",
        "      % (grid.best_params_, grid.best_score_))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best parameters are {'C': 10, 'kernel': 'rbf'} with a score of 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ZtUsN5q5Za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}